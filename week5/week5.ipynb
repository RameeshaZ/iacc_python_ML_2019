{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "\n",
    "* Linear Regression with more than one feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "#Dataset\n",
    "#https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\n",
    "    \n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "#Create Pandas Dataframe from the diabetes data\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "#Add the Target or Output variable and name it progreession\n",
    "diabetes_df['progression'] = diabetes.target\n",
    "\n",
    "#Create a dataframe for the input variable(X) from bmi\n",
    "X = pd.DataFrame(diabetes_df[['age','bp','bmi']])\n",
    "\n",
    "#Y is the output variable\n",
    "Y = diabetes_df['progression']\n",
    "\n",
    "#Split the data into Test and Train sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "\n",
    "# Create linear regression object\n",
    "lr_model = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "lr_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "Y_pred = lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', lr_model.coef_)\n",
    "\n",
    "\n",
    "#The Intercept\n",
    "print('Intercept', lr_model.intercept_)\n",
    "# The mean squared error\n",
    "print(\"Root Mean squared error: %.2f\"\n",
    "      % np.sqrt(mean_squared_error(Y_test, Y_pred)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(Y_test, Y_pred))\n",
    "\n",
    "print('Score : ', lr_model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a DataFrame to compate actual vs Predicted values\n",
    "#compare_df = pd.DataFrame(columns=['Actual Value', 'Predicted Value'])\n",
    "compare_df = Y_test.to_frame(name='Actual Value').reset_index()\n",
    "\n",
    "compare_df['Predicted Value'] = pd.DataFrame(Y_pred, columns=['Predicted Value'])\n",
    "\n",
    "print(compare_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "* Regression technique to predict categorical variables ( Classification )\n",
    "* Example : Predict if an email is spam or not\n",
    "* Logistic regression outputs a value between 0 to 1\n",
    "* This is done using a sigmoid function\n",
    "* Sigmoid function is applied to the linear function\n",
    "* Linear Regression : Y = B0 + B1X\n",
    "* Z = sigmoid(Y)\n",
    "\n",
    "* S(z)=1/1+e^z\n",
    "\n",
    "* s(z) = output between 0 and 1 (probability estimate)\n",
    "* z = input to the function (your algorithmâ€™s prediction e.g. mx + b)\n",
    "* e = base of natural log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "![Sigmoid Function](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/sigmoid.png)\n",
    "\n",
    "\n",
    "------------------\n",
    "\n",
    "### Linear Vs Logistic Regression\n",
    "\n",
    "![Sigmoid Function](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/linvslogreg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cost Function : Cross Entropy or Log Loss is the cost function genereally applied \n",
    "* Minimize Cost Function : Gradient Descent is used to minimize the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Logistic Regression\n",
    "1. Binary Logistic Regression\n",
    "The categorical response has only two 2 possible outcomes. Example: Spam or Not\n",
    "2. Multinomial Logistic Regression\n",
    "Three or more categories without ordering. Example: Predicting which food is preferred more (Veg, Non-Veg, Vegan)\n",
    "3. Ordinal Logistic Regression\n",
    "Three or more categories with ordering. Example: Movie rating from 1 to 5\n",
    "\n",
    "\n",
    "## Evaluating the performance Logistic Regression model\n",
    "\n",
    "\n",
    "### True Positives (TP): These are cases in which we predicted the actual positive clss( predicted  spam  Email accurately ).\n",
    "### True Negatives (TN): Predicted actual negative class( Predicted non-spam email accurately )\n",
    "### False Positives (FP): Predicted spam for a not spam EMail\n",
    "### False Negatives (FN): Predicted not spam for a spam email\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "* Confusion Matric is a table used to visualize the performance of a classification algorithm\n",
    "* In a confusion matrix, TP, TN, FP, FN are displayed in a grid\n",
    "* Confusion matrix is used to calculate other metrics such as Accuracy, Precision, recall, F1-Score etc..\n",
    "\n",
    "![Confusion Matrix](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/cm.jpg)\n",
    "\n",
    "\n",
    "\n",
    "## Precision\n",
    "\n",
    "* Total Percentage of True positives\n",
    "\n",
    "# Recall/Sensitivity\n",
    "\n",
    "* How often are predicted positives True Positives \n",
    "\n",
    "# F1 Score\n",
    "\n",
    "* Weighted average of recall and precision\n",
    "\n",
    "\n",
    "# Example: Predict gender of a person based on their diabetes chart using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_curve,auc,log_loss\n",
    "from sklearn import datasets\n",
    "\n",
    "#Dataset\n",
    "#https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\n",
    "\n",
    "    \n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "#Create Pandas Dataframe from the diabetes data\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "print(diabetes_df.head())\n",
    "\n",
    "#Add the Target or Output variable and name it progreession\n",
    "diabetes_df['progression'] = diabetes.target\n",
    "print(diabetes_df.head())\n",
    "\n",
    "#Create a dataframe for the input variable(X) from age, bp, bmi, pregression\n",
    "X = pd.DataFrame(diabetes_df[['age','bp','bmi','progression']])\n",
    "\n",
    "#Encode male, female as 0 or 1\n",
    "diabetes_df['sex'] = diabetes_df['sex'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "#Y is the output variable\n",
    "Y = diabetes_df['sex']\n",
    "\n",
    "#Split the data into Test and Train sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "#Create the Logistic Regression object\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#Train or fit the model\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "#Generate the prediction score on the test Data set\n",
    "print('Score :', lr.score(X_test,Y_test))\n",
    "\n",
    "#Generate the Confusion Matrix\n",
    "print('Confusion Matrix :', confusion_matrix(Y_test,pred))\n",
    "print(classification_report(Y_test,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms Chart(Scikit-Learn)\n",
    "\n",
    "![Available Algorithms](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/sklearnalg.png)\n",
    "\n",
    "\n",
    "------------------\n",
    "\n",
    "# Support Vector Machines\n",
    "\n",
    "* Can be used for classification and regression\n",
    "* Mainly used for Classification\n",
    "* Goal is to find the optimal plane or hyperplane that separates distinct classes\n",
    "* If the number of input features is 2, then the hyperplane is just a line. If the number of input features is 3, then the hyperplane becomes a two-dimensional plane\n",
    "\n",
    "\n",
    "![SVM](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/svm1.png)\n",
    " \n",
    "* Data points on each side of the hyperplane belong to a specific class\n",
    " \n",
    "* Support vectors are data points that are closest to the Hyperplane\n",
    " \n",
    "* Hyperplanes are built based on the positioning of the support vectors\n",
    " \n",
    "* In the SVM algorithm, we are looking to maximize the margin between the data points and the hyperplane. The loss function that helps maximize the margin is hinge loss.\n",
    " \n",
    " \n",
    " ![Non Linear](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/svmhighdim.png)\n",
    "\n",
    "* For Non Linear data transformatons are used to cast the datset into a higher dimensional plane. These transformations are called kernels.\n",
    " \n",
    "* Cost Function : Hinge loss\n",
    " \n",
    "* Loss Minimization : Gradient Descent or Stochastic Gradient Descent\n",
    " \n",
    "\n",
    "# Example: Predict gender of a person based on their diabetes chart using SVM\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,roc_curve,auc,log_loss\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "\n",
    "#Dataset\n",
    "#https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\n",
    "\n",
    "    \n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "#Create Pandas Dataframe from the diabetes data\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "#Add the Target or Output variable and name it progreession\n",
    "diabetes_df['progression'] = diabetes.target\n",
    "\n",
    "\n",
    "#Create a dataframe for the input variable(X) from bmi\n",
    "X = pd.DataFrame(diabetes_df[['age','bp','bmi','progression']])\n",
    "\n",
    "diabetes_df['sex'] = diabetes_df['sex'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print(diabetes_df.head())\n",
    "\n",
    "#Y is the output variable\n",
    "Y = diabetes_df['sex']\n",
    "\n",
    "print(diabetes_df.head())\n",
    "#Split the data into Test and Train sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "#Create the SVM model object\n",
    "svm_model = SVC()\n",
    "\n",
    "#Train or fit the model\n",
    "svm_model.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "#Generate precitions for the test datset\n",
    "pred = svm_model.predict(X_test)\n",
    "\n",
    "#Generate prediction score\n",
    "print('Score :', svm_model.score(X_test,Y_test))\n",
    "print('Confusion Matrix :', confusion_matrix(Y_test,pred))\n",
    "print(classification_report(Y_test,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "* Used for both Classification and Regression\n",
    "* Supervised learning Algorithm\n",
    "* Goal is to algorithmically split data based on different conditions \n",
    "* Widely used\n",
    "* Easy to interpret and explain\n",
    "\n",
    "![Decisiomn Trees](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/dt1.png)\n",
    "* Learns rules based on input features\n",
    "* The deeper the tree the more complex the rules become\n",
    "* Consits of nodes, edges and leaves \n",
    "* Node - Represents a test or condition\n",
    "* Edge - Represents the outcome \n",
    "* Branch - Represents the class or decision\n",
    "* Can be applied to non-linear data \n",
    "* A general algorithm for a decision tree can be described as follows:\n",
    "\n",
    "* Step 1 : Pick the best attribute/feature. The best attribute is one which best splits or separates the data.\n",
    "* Generate the split condition\n",
    "* Apply Step 1 to the resulting dataset\n",
    "* Continue until the decision is reached\n",
    "\n",
    "## How do decision tree decide on the splits\n",
    "\n",
    "* The Decision Tree algorithms decide how to split the data based on a certain criteria\n",
    "* The two common criteria are : Information Gain(Entopy) or Gini index\n",
    "\n",
    "![Gini Index](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/dtgini.png)\n",
    "\n",
    "### Pruning\n",
    "\n",
    "* Pruning is used to avoid overfitting\n",
    "* Pruning is the technique of reducing the depth of the tree so it doesnt become too complex and eliminates nodes which add less value\n",
    "* Requires manually working with different depths \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Predict gender of a person based on their diabetes chart using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "\n",
    "\n",
    "#Dataset\n",
    "#https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\n",
    "\n",
    "    \n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "#Create Pandas Dataframe from the diabetes data\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "#Add the Target or Output variable and name it progreession\n",
    "diabetes_df['progression'] = diabetes.target\n",
    "\n",
    "\n",
    "#Create a dataframe for the input variable(X) from bmi\n",
    "X = pd.DataFrame(diabetes_df[['age','bp','bmi','progression']])\n",
    "\n",
    "#Encode sex as 0 or 1 for male and female\n",
    "diabetes_df['sex'] = diabetes_df['sex'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "#Y is the output variable\n",
    "Y = diabetes_df['sex']\n",
    "\n",
    "#Split the data into Test and Train sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "#Create the Decision Tree Model\n",
    "dt_model = tree.DecisionTreeClassifier()\n",
    "\n",
    "#Train or Fit the model\n",
    "dt_model.fit(X_train,Y_train)\n",
    "\n",
    "#Generate precitions on the test data \n",
    "pred = dt_model.predict(X_test)\n",
    "\n",
    "#Calculate the prediction score\n",
    "print(dt_model.score(X_test,Y_test))\n",
    "\n",
    "\n",
    "#Plot the Tree\n",
    "plt.figure()\n",
    "tree.plot_tree(dt_model, filled=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "\n",
    "* Random Forests is an algorithm which considers multiple decision trees before making the final decision\n",
    "* The collection of trees used for prediction is called a forest\n",
    "* Each decision tree in the forest is built using random subset of features, thats why they are called random forests\n",
    "* For Regression problems, when it comes time to make a prediction, the random forest takes an average of all the individual decision tree estimates\n",
    "* For Classification,the random forest will take a majority vote for the predicted class\n",
    "\n",
    "\n",
    "![Random Forests](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/randomforests.jpeg)\n",
    "\n",
    "# Example: Predict gender of a person based on their diabetes chart using Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#Dataset\n",
    "#https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\n",
    "\n",
    "    \n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "#Create Pandas Dataframe from the diabetes data\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "#Add the Target or Output variable and name it progreession\n",
    "diabetes_df['progression'] = diabetes.target\n",
    "\n",
    "\n",
    "#Create a dataframe for the input variable(X) from bmi\n",
    "X = pd.DataFrame(diabetes_df[['age','bp','bmi','progression']])\n",
    "\n",
    "diabetes_df['sex'] = diabetes_df['sex'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "#Y is the output variable\n",
    "Y = diabetes_df['sex']\n",
    "\n",
    "#Split the data into Test and Train sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "#Create the Random Forests Model Object, max trees = 100, max_depth=5\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "\n",
    "#Train or Fit the model\n",
    "rf_model.fit(X_train,Y_train)\n",
    "\n",
    "#Generate predictions on test data\n",
    "pred = rf_model.predict(X_test)\n",
    "\n",
    "#Calculate Score\n",
    "print(rf_model.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neigbors\n",
    "\n",
    "* Can be used for Classification and Regression\n",
    "* Mostly used for Classification\n",
    "* The algorithm makes the assumption that data points close to each other are similar\n",
    "* In simple terms, the algorithm calculates the k nearest neighbours and gets the most common class for classification or the average for regression\n",
    "* High Level steps followed by the algorithm:\n",
    "   *  Iterate from 1 to total number of training data points\n",
    "   * Calculate the distance between test data and each row of training data. Euclidean distance is the most popular method. The other metrics that can be used are Chebyshev, cosine, etc.\n",
    "   * Sort the calculated distances in ascending order based on distance values\n",
    "   * Get top k rows from the sorted array\n",
    "   * Get the most frequent class of these rows\n",
    "   * Return the predicted class\n",
    "\n",
    "\n",
    "![KNN](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/knn.webp)\n",
    "\n",
    "\n",
    "\n",
    "# Example: Predict gender of a person based on their diabetes chart using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#Dataset\n",
    "#https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\n",
    "\n",
    "    \n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "#Create Pandas Dataframe from the diabetes data\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "#Add the Target or Output variable and name it progreession\n",
    "diabetes_df['progression'] = diabetes.target\n",
    "\n",
    "\n",
    "#Create a dataframe for the input variable(X) from bmi\n",
    "X = pd.DataFrame(diabetes_df[['age','bp','bmi','progression']])\n",
    "\n",
    "diabetes_df['sex'] = diabetes_df['sex'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "#Y is the output variable\n",
    "Y = diabetes_df['sex']\n",
    "\n",
    "#Split the data into Test and Train sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "#Create the KNN object, with k = 3\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Train and fit the model\n",
    "knn_model.fit(X_train,Y_train)\n",
    "\n",
    "#Generate pridictions on the test dataset\n",
    "pred = knn_model.predict(X_test)\n",
    "\n",
    "#Calculate the model score\n",
    "print(knn_model.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K - Means\n",
    "\n",
    "* Un-Supervised Learning technique\n",
    "* Used for clustering data into different groups or cluster\n",
    "* Example : Recommendation Engines\n",
    "* The center of the cluster is called centroid\n",
    "* K means divides the data into k clusters\n",
    "* The goal of K-Means algorithm is to minimize the sum of distances between the points and their respective cluster centroid.\n",
    "\n",
    "* Clustering process\n",
    "* Step 1 : Select the number of clusters to find in the data (k)\n",
    "* Step 2 : Select k random data points as the initial centroids\n",
    "* Step 3 : Assign every point to the cluster closest to it\n",
    "* Step 4 : Calculate the centroid of the clusters that are now created\n",
    "* Repeat Step 3 and 4 until one of the following conditions is met \n",
    "    * The centroids do not change\n",
    "    * The points stay in the same clusters\n",
    "    * The max number of iterations is reached\n",
    "\n",
    "\n",
    "\n",
    "![KMeans](https://raw.githubusercontent.com/soulzcore/iacc_python_ML_2019/master/week5/img/kmeans.gif)\n",
    "\n",
    "\n",
    "\n",
    "# Example: Find 2 Clusters in the diabetes data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Dataset\n",
    "#https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\n",
    "\n",
    "    \n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "#Create Pandas Dataframe from the diabetes data\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "#Add the Target or Output variable and name it progreession\n",
    "diabetes_df['progression'] = diabetes.target\n",
    "\n",
    "\n",
    "#Create a dataframe for the input variable(X) from bmi\n",
    "X = pd.DataFrame(diabetes_df[['age','progression']])\n",
    "\n",
    "#Create the KMeans object,with k = 2\n",
    "km_model = KMeans(n_clusters=2, random_state=0)\n",
    "\n",
    "#Fit the model\n",
    "km_model.fit(X)\n",
    "\n",
    "#Print the cluster centroids\n",
    "print(km_model.cluster_centers_)\n",
    "\n",
    "#Plot the clusters\n",
    "plt.figure('K-means with 3 clusters')\n",
    "plt.scatter(X.values[:, 0], X.values[:, 1], c=km_model.labels_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
