{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Introduction to Machine Learning\n\n# What is it and Why do I care?\n\n![Google trends](img/gootrend.jpg)\n\n![Best Jobs](img/mljobs.jpg)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 1. Learning Resources\n\n* Machine Learning by Stanford : https://www.coursera.org/learn/machine-learning\n* Amazon Machine Learning University : https://aws.training/machinelearning\n* Google Machine Learning Course : https://developers.google.com/machine-learning/crash-course\n* Fast.ai courses : https://www.fast.ai/\n* Kaggle Courses : https://www.kaggle.com/learn/overview\n* Book : Data Science from Scratch\n* Book : Introduction to Machine Learning with Python"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 1. Data Landscape\n\n![image.png](img/dataland.png)",
      "attachments": {}
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 2. AI vs ML vs DL vs DS\n\n\n![ML Meme](img/mlmeme.jpeg)\n\n\n\n--------------\n\n\n![image.png](img/techcomp.png)",
      "attachments": {}
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 3. Common Machine Learning terminology\n\n\n\n## Scalar\n\n## Vector\n\n## Matrix\n\n## CPU\n\n## GPU\n\n## Distributed\n\n## Batch\n\n## Realtime\n\n## Algorithm\n\n## Model\n\n## Line\n\n## Plane\n\n## Hyperplane\n\n## Linear\n\n## Non Linear\n\n## Binary\n\n## Non- Binary\n\n## Multi Variate\n\n## Numerical Variables\n\n## Categorical Variables\n\n## Nominal Variables\n\n## Ordinal Variables\n\n## Features\n\n## Label\n\n## Feature Engineering\n\n## Feature Selection\n\n## Predict/Inference\n\n## Train\n\n## Test\n\n## Validation\n\n## Scoring\n\n## Overfitting\n\n## Underfitting\n\n## Supervised\n\n## Unsupervised\n\n## Semi Supervised\n\n## Reinforcement Learning\n\n## Neural Networks\n\n## Deep Learning\n\n## Regression\n\n## Classification\n\n## Clustering\n\n## Transformation\n\n## Scaling\n\n## Optimization\n\n## Accuracy\n\n## Cost function\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 4. Machine Learning Categories\n\n![image.png](img/typeofml.png)\n\n![title](img/MlCat.jpg)\n\n",
      "attachments": {}
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![image.png](img/algtree.png)",
      "attachments": {}
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Supervised Learning\n\n\n* Definition : Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples.\n\n* The example Input-Output pair is called the training data\n\n* Input variables or data are the identifiers or attributes of the example that is being considered\n\n* Output or a label is the attribute that is correctly associated with the Input\n\n* Example of Sales data:\n\n* Input variables can be Month(January), day of the week(Sunday), weather(20), date(15) \n\n* Output variable can be : total sales($100,000)\n\n* Lets call the Input Variables/vector : x\n\n* Lets call the Output : Y\n\n* Simply put the process of finding a function f such that : y = f(x) is called supervised learning\n\n* It called learning because the algorithm iteratively corrects or optimizes the function f until it achives an acceptable level of accuracy\n\n* Supervised Machine Learning can be further classified into two types : Classification and Clustering\n\n![Classification VS Regression](img/clareg.jpeg)\n\n\n## Regression\n\n* Regression is the technique of predicting a continous numerical value for the output variable Y\n\n* Examples : \n\n* Predicting weather\n\n* Predicting value of a house\n\n* Forecasting sales for the next week\n\n\n\n## Classification\n\n* Classification is the technique of predicting labels or discrete values for the output variable Y\n\n* Example : \n\n* Predicting gender of a baby\n\n* Predicting winner of NFL\n\n\n\n# Machine Learning Algorithms\n## Linear Regression\n\n* Linear Regression is one of the most well known algorithms in M.L\n* It is both statistical and M.L algorithm\n* The basic assumption of Linear Regression Model is that the input X and Output Y have a linear relationship and that a Linear equation can be written such that Y can be calculated from a value of X\n\n![Linear Vs NonLinear](img/linear-nonlinear-relationships.png)\n* When there is a single input variable X, it is called Simple Regression\n\n* A Simple linear equation\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y = B0 + B1x\n\n#Y is the value to be predicted ( Example Value of house)\n#x is the input variable( Example Year it was built)\n#B0 and B1 are called parameters",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Linear Regression Explained](img/LinearRegExpl.png)\n\n\n* y — is the value of the dependent variable\n* β₀ — is the y-intercept of the line means where the line intersects the Y-axis\n* β₁ — The slope or gradient of the line(Coefficient)\n* x — The value of the independent variable\n* u — The residual or noise that are caused by unexplained factors\n\n* In case of Linear Regression the model basically learns the best values of the parameters β₀ and β₁\n\n* Once the model learns the parameters it can calculate the value of y based on a value of x\n\n## How do models learn the parameters\n\n* Multiple different ways of learning parameters\n\n* Example : Minimising Cost Function, Orninary Least Square\n\n## Cost Function\n\n* Cost Functions are used to determine or estimate the difference between predicted vs actual value\n\n* Example Cost Function : Mean Squared Error\n\n* Mean square error (MSE) is the average squared loss per example over the whole dataset. To calculate MSE, sum up all the squared losses for individual examples and then divide by the number of examples:\n\n![MSE](img/MSE.png)\n\n* The cost function (you may also see this referred to as loss or error.) can be estimated by iteratively running the model to compare estimated predictions against “ground truth” — the known values of y.\n\n* The objective of a ML model, therefore, is to find parameters, weights or a structure that minimises the cost function.\n\n\n## Gradiant Descent\n\n* Gradiant Descent is an algorithm used to minimze the cost function\n\n![Gradient Descent](img/GD.gif)\n\n* As the model iterates, it gradually converges towards a minimum where further tweaks to the parameters produce little or zero changes in the loss\n\n\n## Putting it all together\n\n![How does it work](img/LRgif.gif)\n\n* Once the model is trained, it learns the values of B0 and B1\n* Now these can be used to predict the value of y for any arbitary value of x\n\n\n\n\n\n## Implementing the algorithm in python\n\n* Linear regression can be implemented in pure python with the help with libraries like Numpy\n* We will have to write our own code to calculate things like : MSE, gradiant descent, co-variance\n* We will have to write the code to train the model iteratively on the dataset and calculate the accuracy etc..\n* Or like everything else in Python we can re-use an existing framework/Module/Libary\n\n\n\n## Machine Learning Frameworks\n\n* Examples : Scikit Learn, SparkML, Tensor Flow, Caffe, Pytorch etc..\n* These frameworks have optimized implementations of almost all common M.L algorithms\n\n\n## Scikit Learn\n\n* One of the most popular framework for Machine Learning\n* Simple and efficient tools for data mining and data analysis\n* Accessible to everybody, and reusable in various contexts\n* Built on NumPy, SciPy, and matplotlib\n* Open source, commercially usable - BSD license\n\n\n## Train & Test Split\n\n* The data used for building models is split between train and test sets\n* Typically 80% of the data is used for training and 20% is used for testing\n* For massive data sets, its commomn to use 95% of data for training and 5% for testing\n* Once the Model is trained on the Train set, it is used to predict the outputs of the Test set\n* The Models performance is determined based on how the predicted values compare to the actual values\n\n\n## Model Performance Evaluation\n\n**Root Mean Squared Error**\n\n* RSME is the standard deviation of prediction errors\n* RMSE tells you how concentrated the data is around the line of best fit\n\n\n**R2**\n\n* R-squared is always between 0 and 100%\n* 0% represents a model that does not explain any of the variation in the response variable around its mean\n* 100% represents a model that explains all of the variation in the response variable around its mean\n* Used as Model score\n\n* The higher the value of R2 the better(some conditions apply)\n\n\n## Model Fit\n\n## Underfit, Balanced and Overfit\n\n![Model Fit](img/fit.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Linear Regression With Scikit Learn Example\n\n* In this example we will predict the progression of diabetes after one year based on given features \n* We will use the built in diabetes dataset of scikit learn\n* https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\n* We will do some basic analysis, split the data into Train and test split, fit the model, get predictions for the test set and evaluate the model\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\n\n#Dataset\n#https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\n\n    \n# Load the diabetes dataset\ndiabetes = datasets.load_diabetes()\n\n\nprint('Data Set Keys :', diabetes.keys())\n\nprint('Feature Names : ', diabetes.feature_names)\n\nprint('Description :', diabetes.DESCR)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Create Pandas Dataframe from the diabetes data\ndiabetes_df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\nprint(diabetes_df.head())\n\n#Add the Target or Output variable and name it progreession\ndiabetes_df['progression'] = diabetes.target\nprint(diabetes_df.head())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Generate scatter plot to determine correlation between features and the progression(output)**"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Generate scatter plot to determine correlation between features and the progression(output)\nplt.figure(figsize=(20, 5))\nfeatures = ['bmi', 'age', 'bp']\ntarget = diabetes_df['progression']\n\nfor i, col in enumerate(features):\n    plt.subplot(1, len(features) , i+1)\n    x = diabetes_df[col]\n    y = target\n    plt.scatter(x, y, marker='o')\n    plt.title(col)\n    plt.xlabel(col)\n    plt.ylabel('diabetes_df')\n    \nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* **BMI and BP seem to have a linear relationship whereas age does not**\n* **For the sake of this example, lets select BMI as out input feature for simple linear regression**"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n#Create a dataframe for the input variable(X) from bmi\nX = pd.DataFrame(diabetes_df['bmi'].values.reshape(-1, 1))\n\n#Y is the output variable\nY = diabetes_df['progression']\n\n#Split the data into Test and Train sets\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Create Linear Regression Object, fit the model and generate predictions on the test data set**"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create linear regression object\nlr_model = linear_model.LinearRegression()\n\n# Train the model using the training sets\nlr_model.fit(X_train, Y_train)\n\n# Make predictions using the testing set\nY_pred = lr_model.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Generate the Model parameters and performance meterics**"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# The coefficients\nprint('Coefficients: \\n', lr_model.coef_)\n\n\n#The Intercept\nprint('Intercept', lr_model.intercept_)\n# The mean squared error\nprint(\"Root Mean squared error: %.2f\"\n      % np.sqrt(mean_squared_error(Y_test, Y_pred)))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(Y_test, Y_pred))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Plot outputs and visualize the best fit line\nplt.scatter(X_test, Y_test,  color='black')\nplt.plot(X_test, Y_pred, color='blue', linewidth=3)\n\nplt.xticks(())\nplt.yticks(())\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Create a DataFrame to compate actual vs Predicted values\n#compare_df = pd.DataFrame(columns=['Actual Value', 'Predicted Value'])\ncompare_df = Y_test.to_frame(name='Actual Value').reset_index()\n\ncompare_df['Predicted Value'] = pd.DataFrame(Y_pred, columns=['Predicted Value'])\n\nprint(compare_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}